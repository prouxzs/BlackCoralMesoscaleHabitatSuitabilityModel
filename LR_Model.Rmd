---
title: "Modeling Black Coral Presence on the West Florida Escarpment"
author: "Zach Proux"
date: "3/28/2018"
output: html_document
---

# Please be sure to read the "README.md" in the repository before proceeding.

```{r}
# Load necessary packages
library(raster)
library(rgdal)
library(sp)
```

```{r}
# Import coral presence/absence data and make it a data.frame
bcoral = read.csv("./Data/Black_Coral_P&amp;A.csv")
coral = data.frame(bcoral)
```

```{r}
# Reproject lat_long to WGS 1984 World Mercator to match rasters
lon = coral$LongitudeDD
lat = coral$LatitudeDD
xy = SpatialPoints(cbind(lon, lat), proj4string=CRS("+proj=longlat"))
xy.UTM = spTransform(xy, CRS("+init=epsg:32616"))
UTM.latlon = as.data.frame(xy.UTM)
```

```{r}
# Import raster data 
aspect = raster("./Data/Clip_Aspect1.tif")
slope = raster("./Data/Clip_Slope1.tif")
depth = raster("./Data/Clip_Depth1.tif")
intensity = raster("./Data/Clip_Intensity1.tif")
```

```{r}
# Group files for stacking
files = c("./Data/Clip_Aspect1.tif", "./Data/Clip_Slope1.tif", "./Data/Clip_Depth1.tif", "./Data/Clip_Intensity1.tif")
```

```{r}
# Stack the raster data
RaStack = stack(files, RAT = TRUE)
```

```{r}
# Extract environmental variables for each coordinate
EnVar = extract(RaStack, xy.UTM)
EnVar.df = as.data.frame(EnVar)
# Bind environmental variables to their respective coral presence/absence observations
ModVar = cbind(coral, EnVar.df, UTM.latlon)
# Eliminate observations with no environmental data
work = ModVar[complete.cases(ModVar),]
```

```{r}
# Use environmental variables as inputs in a binomial logistic regression
mod1 = glm(work$Presence ~ work$Clip_Depth1 + work$Clip_Slope1 + work$Clip_Aspect1
           + work$Clip_Intensity1 + work$lon + work$lat, family = "binomial")
# AIC = 725.18
# Only Aspect was significant
# Considering longitude and depth are related as you move westward from the coast
# of West Florida, I chose to only use depth because it may also be indicative of 
# other water quality properties or physical parameters.
```

```{r}
# Narrow down the number of independent variables based on significance
mod2 = glm(work$Presence ~ work$Clip_Slope1 + work$Clip_Aspect1
           + work$Clip_Intensity1 + work$Clip_Depth1 + work$lat, family = "binomial")
# AIC = 725.44
# Depth and Aspect were significant.  Slope and intensity were trending.
# Latitude was not significant.
```

```{r}
mod3 = glm(Presence ~ Clip_Slope1 + Clip_Aspect1 + Clip_Intensity1 + Clip_Depth1,
           data = work, family = "binomial")
summary(mod3)
# AIC = 723.59
# All variables significant except intensity
```

```{r}
mod4 = glm(work$Presence ~ work$Clip_Slope1 + work$Clip_Aspect1 + work$Clip_Depth1,
           family = "binomial")
# AIC = 724.27
# Performed slightly worse than mod3 so I left intensity in.
# Mod3 is the winner
```

```{r}
# Cut data frame to just the variables I want
work.cut = subset(work, select = c(Clip_Aspect1, Clip_Slope1, Clip_Depth1, 
                                   Clip_Intensity1, Presence))
```

```{r}
# Cross-Validate the glm 
library(boot)
k = 10
cv.mod3 = cv.glm(work.cut, mod3, K = k)
# Delta = 0.234
```

```{r}
# Alternative Cross-validation Method
# Split the dataframe into two randomly sorted data frames 
allrows = 1:nrow(work.cut)
trainrows = sample(allrows, replace = F, size = 0.5*length(allrows))
testrows = allrows[-trainrows]
train = work.cut[trainrows,]
test = work.cut[testrows,]
```

```{r}
# Create models from training dataframe
train.mod = glm(Presence ~ Clip_Aspect1 + Clip_Slope1 + Clip_Intensity1 + Clip_Depth1,
                data = train, family = "binomial")
summary(train.mod)
# AIC = 370.7 
# Predict response 0-1 based on test data frame
pre.test = predict.glm(train.mod, test, type = "response")
# Calculate Root Mean Square to test model performance
RMSE = mean((test$Presence - pre.test)^2)
# RMSE = .02201
```

```{r}
# Create model from testing dataframe
test.mod = glm(Presence ~ Clip_Aspect1 + Clip_Slope1 + Clip_Intensity1 + Clip_Depth1,
                data = test, family = "binomial")
summary(test.mod)
# AIC = 358.42
# Predict response 0-1 based on train data frame
pre.train = predict.glm(test.mod, train, type = "response")
# Calculate Root Mean Square to test model performance
RMSE2 = mean((train$Presence - pre.train)^2)
# RMSE2 = 0.02263
```

```{r}
# Produce predictive values for each 10m pixel
mod3.map = predict(RaStack, mod3)
# Plot likelihood of occurrence on map
plot(mod3.map)
```
# 
#
#
#
#
# Below this point, I am still working and you should not expect this code to run.
#
#
#
#
#
```{r}
# Check residuals
```

```{r}
# Check model for spatial dependence
sr = apply(work, 1, function(x) sum(x > 0))
plot(UTM.latlon, cex=sr/max(sr))
col_brks = hist(sr, plot=F)$breaks
col_indices = as.numeric(cut(sr, col_brks))
cols = rev(terrain.colors(length(col_brks)))
plot(UTM.latlon, cex=2, pch=19, col=cols[col_indices])
```

